{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "# Load Keras Libraries\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train-test data\n",
    "train_data = pd.read_csv('../train.csv')\n",
    "test_data = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top level categories are: ['Mobile', 'Fashion', 'Beauty']\n",
      "There are 27 categories in Mobile\n",
      "There are 14 categories in Fashion\n",
      "There are 17 categories in Beauty\n"
     ]
    }
   ],
   "source": [
    "# categories: naming \n",
    "import json\n",
    "with open('../categories.json','r') as f:\n",
    "    allCat = json.load(f)\n",
    "print('The top level categories are: {}'.format(list(allCat.keys())))\n",
    "\n",
    "\n",
    "print('There are {} categories in Mobile'.format(len(allCat['Mobile'])))\n",
    "print('There are {} categories in Fashion'.format(len(allCat['Fashion'])))\n",
    "print('There are {} categories in Beauty'.format(len(allCat['Beauty'])))\n",
    "\n",
    "mobCat = sorted(list(allCat['Mobile'].values()))\n",
    "fasCat = sorted(list(allCat['Fashion'].values()))\n",
    "beuCat = sorted(list(allCat['Beauty'].values()))\n",
    "\n",
    "folder_path_dict = {i:'Mobile' for i in mobCat}\n",
    "folder_path_dict.update({i:'Fashion' for i in fasCat})\n",
    "folder_path_dict.update({i:'Beauty' for i in beuCat})\n",
    "\n",
    "##\n",
    "numerical2label = {}\n",
    "labels = allCat\n",
    "\n",
    "for master_label in labels.keys():\n",
    "    master_dict = labels[master_label]\n",
    "    for item_name, item_idx in master_dict.items():\n",
    "        numerical2label[item_idx] = item_name\n",
    "        \n",
    "label2numerical = {}\n",
    "for item_idx, item_name in numerical2label.items():\n",
    "    label2numerical[item_name] = item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file paths accordingly in train_df\n",
    "train_df = train_data.copy()\n",
    "\n",
    "def update_file_path(inp):\n",
    "    #print(inp)\n",
    "    x = inp[0]\n",
    "    cat = inp[1]\n",
    "    path_segs = x.split('/')\n",
    "    \n",
    "    path_map = {'beauty_image':'Beauty', 'fashion_image':'Fashion', 'mobile_image':'Mobile'}\n",
    "    base_path = 'Train/' + path_map[path_segs[0]]\n",
    "    rel_path = path_segs[1]\n",
    "    rel_segs = rel_path.split('.')\n",
    "    if len(rel_segs) == 1:\n",
    "        rel_path = rel_path + '.jpg'\n",
    "    return base_path + '/' + str(cat)+ '/' + rel_path\n",
    "\n",
    "train_df['new_path'] = train_df.loc[:,['image_path','Category']].apply(lambda x: update_file_path(x),axis=1)\n",
    "train_df['meta_cat'] = train_df.loc[:,'image_path'].apply(lambda x: x.split('/')[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160330, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lood data for mobile categories (CHANGE here for other categories)\n",
    "train_byCat = train_df.groupby('meta_cat')\n",
    "cur_cat = 'mobile_image'\n",
    "cat_train = train_byCat.get_group(cur_cat)\n",
    "cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "# input shape\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.MobileNet(weights='imagenet', include_top=False, \n",
    "                                        input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "last_layer = base_model.output\n",
    "neck = GlobalAveragePooling2D()(last_layer)\n",
    "\n",
    "# Base Mobilenet   Model\n",
    "model = Model(inputs=base_model.input, outputs=neck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "base_dir = '/mnt/disks/NDSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160330 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generator-1\n",
    "batch_size = 50\n",
    "generator = datagen.flow_from_dataframe(\n",
    "        dataframe=cat_train,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206/3206 [==============================] - 2754s 859ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate features for train samples\n",
    "num_samples = generator.n\n",
    "generator.reset()\n",
    "\n",
    "bottleneck_features_mobile = model.predict_generator(\n",
    "        generator, num_samples // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mobile_bottleneck_part_1.npy', 'wb') as f:\n",
    "    np.save(f, bottleneck_features_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rem = len(cat_train)-len(bottleneck_features_mobile)\n",
    "N_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_rem = cat_train.tail(N_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generator-1\n",
    "batch_size = 1\n",
    "generator_rem = datagen.flow_from_dataframe(\n",
    "        dataframe=mob_rem,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_rem = generator_rem.n\n",
    "generator_rem.reset()\n",
    "\n",
    "bottleneck_features_mobile_rem = model.predict_generator(\n",
    "        generator_rem, num_samples_rem // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0132027"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(bottleneck_features_mobile_rem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.828734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(bottleneck_features_mobile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4925256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(bottleneck_features_mobile[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate\n",
    "X_IMG_MOB_TRAIN = np.concatenate((bottleneck_features_mobile,bottleneck_features_mobile_rem), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160330, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_IMG_MOB_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_IMG_MOB_TRAIN.npy', 'wb') as f:\n",
    "    np.save(f, X_IMG_MOB_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_IMG_MOB_TRAIN.npy', 'rb') as f:\n",
    "    X_IMG_MOB_TRAIN= np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4925256"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_IMG_MOB_TRAIN[-31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mob = X_IMG_MOB_TRAIN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_y = cat_train.Category.values\n",
    "mob_targets = np.zeros((n_mob, 58))\n",
    "mob_targets[np.arange(n_mob), mob_y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img_input (InputLayer)       (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc-1 (Dense)                 (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 58)                29754     \n",
      "=================================================================\n",
      "Total params: 1,608,250\n",
      "Trainable params: 1,606,202\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Beauty model\n",
    "img_input = Input(shape=(1024,), name='img_input')\n",
    "x = BatchNormalization()(img_input)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu', name= 'fc-1')(x) # dense 1\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation='relu')(x) #dense layer 2\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(58, activation = 'softmax', name = 'out_layer')(x)\n",
    "\n",
    "# Base Mobilenet   Model\n",
    "\n",
    "Mob_model = Model(inputs=img_input, outputs=out)\n",
    "\n",
    "Mob_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "Mob_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NYRS_gen(X, y, batch_size):\n",
    "    \n",
    "    n_batches = math.floor(len(X) / batch_size)\n",
    "    \n",
    "    while True: \n",
    "        X,y = shuffle(X,y) # Shuffle the index.\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            X_batch = X[i*batch_size:(i+1)*batch_size]\n",
    "            y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5010/5010 [==============================] - 30s 6ms/step - loss: 1.6486 - acc: 0.4869 - val_loss: 1.4490 - val_acc: 0.5516\n",
      "Epoch 2/10\n",
      "5010/5010 [==============================] - 29s 6ms/step - loss: 1.6229 - acc: 0.4943 - val_loss: 1.4336 - val_acc: 0.5587\n",
      "Epoch 3/10\n",
      "5010/5010 [==============================] - 28s 6ms/step - loss: 1.6105 - acc: 0.4994 - val_loss: 1.4437 - val_acc: 0.5556\n",
      "Epoch 4/10\n",
      "5010/5010 [==============================] - 29s 6ms/step - loss: 1.5928 - acc: 0.5047 - val_loss: 1.4427 - val_acc: 0.5581\n",
      "Epoch 5/10\n",
      "5010/5010 [==============================] - 28s 6ms/step - loss: 1.5699 - acc: 0.5116 - val_loss: 1.4372 - val_acc: 0.5574\n",
      "Epoch 6/10\n",
      "5010/5010 [==============================] - 28s 6ms/step - loss: 1.5552 - acc: 0.5168 - val_loss: 1.4357 - val_acc: 0.5572\n",
      "Epoch 7/10\n",
      "5010/5010 [==============================] - 30s 6ms/step - loss: 1.5490 - acc: 0.5194 - val_loss: 1.4234 - val_acc: 0.5603\n",
      "Epoch 8/10\n",
      "5010/5010 [==============================] - 29s 6ms/step - loss: 1.5319 - acc: 0.5248 - val_loss: 1.4269 - val_acc: 0.5611\n",
      "Epoch 9/10\n",
      "5010/5010 [==============================] - 29s 6ms/step - loss: 1.5140 - acc: 0.5287 - val_loss: 1.4256 - val_acc: 0.5658\n",
      "Epoch 10/10\n",
      "5010/5010 [==============================] - 29s 6ms/step - loss: 1.5103 - acc: 0.5301 - val_loss: 1.4296 - val_acc: 0.5615\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "import math\n",
    "\n",
    "N = len(X_IMG_MOB_TRAIN)\n",
    "\n",
    "X_IMG_MOB_TRAIN, mob_targets = shuffle(X_IMG_MOB_TRAIN, mob_targets)\n",
    "\n",
    "N_train = int(0.8*N)\n",
    "\n",
    "X_train = X_IMG_MOB_TRAIN[:N_train]\n",
    "y_train = mob_targets[:N_train]\n",
    "\n",
    "X_val = X_IMG_MOB_TRAIN[N_train:]\n",
    "y_val = mob_targets[N_train:]\n",
    "\n",
    "n_steps = len(X_IMG_MOB_TRAIN) // batch_size\n",
    "\n",
    "batch_gen = NYRS_gen(X_train, y_train, 32)\n",
    "\n",
    "history = Mob_model.fit_generator(batch_gen, epochs=10, \n",
    "                              steps_per_epoch=n_steps, \n",
    "                              validation_data=(X_val,y_val),\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file paths accordingly in train_df\n",
    "test_df = test_data.copy()\n",
    "\n",
    "def update_test_file_path(inp):\n",
    "\n",
    "    path_segs = inp.split('/')\n",
    "    \n",
    "    path_map = {'beauty_image':'Beauty', 'fashion_image':'Fashion', 'mobile_image':'Mobile'}\n",
    "    base_path = 'Test/' + path_map[path_segs[0]]\n",
    "    rel_path = path_segs[1]\n",
    "    \n",
    "    rel_segs = rel_path.split('.')\n",
    "    if len(rel_segs) == 1:\n",
    "        rel_path = rel_path + '.jpg'\n",
    "        \n",
    "    return base_path + '/'  + rel_path\n",
    "\n",
    "test_df['new_path'] = test_df.loc[:,'image_path'].apply(lambda x: update_test_file_path(x))\n",
    "test_df['meta_cat'] = test_df.loc[:,'image_path'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40417, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lood data for mobile categories (CHANGE here for other categories)\n",
    "test_byCat = test_df.groupby('meta_cat')\n",
    "cur_cat = 'mobile_image'\n",
    "cat_test = test_byCat.get_group(cur_cat)\n",
    "cat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1. / 255)\n",
    "base_dir = '/mnt/disks/NDSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40417 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generator-test\n",
    "batch_size = 50\n",
    "generator_test = datagen_test.flow_from_dataframe(\n",
    "        dataframe=cat_test,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808/808 [==============================] - 582s 720ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate features for  test samples\n",
    "num_samples = generator_test.n\n",
    "generator_test.reset()\n",
    "\n",
    "bottleneck_features_mobile_test = model.predict_generator(\n",
    "        generator_test, num_samples // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_TEST_Mobile_bottleneck_part_1.npy', 'wb') as f:\n",
    "    np.save(f, bottleneck_features_mobile_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rem = len(cat_test)-len(bottleneck_features_mobile_test)\n",
    "N_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>image_path</th>\n",
       "      <th>new_path</th>\n",
       "      <th>meta_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172397</th>\n",
       "      <td>1781957365</td>\n",
       "      <td>nokia 5.1 plus ram 3gb 32gb garansi resmi 1 ta...</td>\n",
       "      <td>mobile_image/3dbd99b9d999d326d8ae57f7ad1f1b3e.jpg</td>\n",
       "      <td>Test/Mobile/3dbd99b9d999d326d8ae57f7ad1f1b3e.jpg</td>\n",
       "      <td>mobile_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172398</th>\n",
       "      <td>1839851276</td>\n",
       "      <td>big promo add whatshap 0821 9127 5399 iphone 7...</td>\n",
       "      <td>mobile_image/6d45e5c7e36ac897f58a9f72ff4bf0b8.jpg</td>\n",
       "      <td>Test/Mobile/6d45e5c7e36ac897f58a9f72ff4bf0b8.jpg</td>\n",
       "      <td>mobile_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172399</th>\n",
       "      <td>955369303</td>\n",
       "      <td>datang lagi sharp r1 ram 3gb 32gb gratis silic...</td>\n",
       "      <td>mobile_image/08f68bb1cc3f381364776ac5cfd9e45e.jpg</td>\n",
       "      <td>Test/Mobile/08f68bb1cc3f381364776ac5cfd9e45e.jpg</td>\n",
       "      <td>mobile_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172400</th>\n",
       "      <td>1638035772</td>\n",
       "      <td>sony xperia z5 premium au ram 3gb rom 32gb sec...</td>\n",
       "      <td>mobile_image/1d0610ea0f43d75ecc3ff951f6c647d4.jpg</td>\n",
       "      <td>Test/Mobile/1d0610ea0f43d75ecc3ff951f6c647d4.jpg</td>\n",
       "      <td>mobile_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172401</th>\n",
       "      <td>1498091427</td>\n",
       "      <td>xiaomi mi 8 ram 6 128gb black</td>\n",
       "      <td>mobile_image/6649fa043a7b2eebda6ed904c966a14b.jpg</td>\n",
       "      <td>Test/Mobile/6649fa043a7b2eebda6ed904c966a14b.jpg</td>\n",
       "      <td>mobile_image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            itemid                                              title  \\\n",
       "172397  1781957365  nokia 5.1 plus ram 3gb 32gb garansi resmi 1 ta...   \n",
       "172398  1839851276  big promo add whatshap 0821 9127 5399 iphone 7...   \n",
       "172399   955369303  datang lagi sharp r1 ram 3gb 32gb gratis silic...   \n",
       "172400  1638035772  sony xperia z5 premium au ram 3gb rom 32gb sec...   \n",
       "172401  1498091427                      xiaomi mi 8 ram 6 128gb black   \n",
       "\n",
       "                                               image_path  \\\n",
       "172397  mobile_image/3dbd99b9d999d326d8ae57f7ad1f1b3e.jpg   \n",
       "172398  mobile_image/6d45e5c7e36ac897f58a9f72ff4bf0b8.jpg   \n",
       "172399  mobile_image/08f68bb1cc3f381364776ac5cfd9e45e.jpg   \n",
       "172400  mobile_image/1d0610ea0f43d75ecc3ff951f6c647d4.jpg   \n",
       "172401  mobile_image/6649fa043a7b2eebda6ed904c966a14b.jpg   \n",
       "\n",
       "                                                new_path      meta_cat  \n",
       "172397  Test/Mobile/3dbd99b9d999d326d8ae57f7ad1f1b3e.jpg  mobile_image  \n",
       "172398  Test/Mobile/6d45e5c7e36ac897f58a9f72ff4bf0b8.jpg  mobile_image  \n",
       "172399  Test/Mobile/08f68bb1cc3f381364776ac5cfd9e45e.jpg  mobile_image  \n",
       "172400  Test/Mobile/1d0610ea0f43d75ecc3ff951f6c647d4.jpg  mobile_image  \n",
       "172401  Test/Mobile/6649fa043a7b2eebda6ed904c966a14b.jpg  mobile_image  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mob_rem = cat_test.tail(N_rem)\n",
    "test_mob_rem.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generator-1\n",
    "datagen_test_rem = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 1\n",
    "test_generator_rem = datagen_test_rem.flow_from_dataframe(\n",
    "        dataframe=test_mob_rem,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_rem = test_generator_rem.n\n",
    "test_generator_rem.reset()\n",
    "\n",
    "test_bottleneck_features_mobile_rem = model.predict_generator(\n",
    "        test_generator_rem, num_samples_rem // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IMG_MOB_TEST = np.concatenate((bottleneck_features_mobile_test,test_bottleneck_features_mobile_rem), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_IMG_MOB_TEST.npy', 'wb') as f:\n",
    "    np.save(f, X_IMG_MOB_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu_1)",
   "language": "python",
   "name": "tf_gpu_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
