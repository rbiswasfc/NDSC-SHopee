{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "# Load Keras Libraries\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train-test data\n",
    "train_data = pd.read_csv('../train.csv')\n",
    "test_data = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top level categories are: ['Mobile', 'Fashion', 'Beauty']\n",
      "There are 27 categories in Mobile\n",
      "There are 14 categories in Fashion\n",
      "There are 17 categories in Beauty\n"
     ]
    }
   ],
   "source": [
    "# categories: naming \n",
    "import json\n",
    "with open('../categories.json','r') as f:\n",
    "    allCat = json.load(f)\n",
    "print('The top level categories are: {}'.format(list(allCat.keys())))\n",
    "\n",
    "\n",
    "print('There are {} categories in Mobile'.format(len(allCat['Mobile'])))\n",
    "print('There are {} categories in Fashion'.format(len(allCat['Fashion'])))\n",
    "print('There are {} categories in Beauty'.format(len(allCat['Beauty'])))\n",
    "\n",
    "mobCat = sorted(list(allCat['Mobile'].values()))\n",
    "fasCat = sorted(list(allCat['Fashion'].values()))\n",
    "beuCat = sorted(list(allCat['Beauty'].values()))\n",
    "\n",
    "folder_path_dict = {i:'Mobile' for i in mobCat}\n",
    "folder_path_dict.update({i:'Fashion' for i in fasCat})\n",
    "folder_path_dict.update({i:'Beauty' for i in beuCat})\n",
    "\n",
    "##\n",
    "numerical2label = {}\n",
    "labels = allCat\n",
    "\n",
    "for master_label in labels.keys():\n",
    "    master_dict = labels[master_label]\n",
    "    for item_name, item_idx in master_dict.items():\n",
    "        numerical2label[item_idx] = item_name\n",
    "        \n",
    "label2numerical = {}\n",
    "for item_idx, item_name in numerical2label.items():\n",
    "    label2numerical[item_name] = item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file paths accordingly in train_df\n",
    "train_df = train_data.copy()\n",
    "\n",
    "def update_file_path(inp):\n",
    "    #print(inp)\n",
    "    x = inp[0]\n",
    "    cat = inp[1]\n",
    "    path_segs = x.split('/')\n",
    "    \n",
    "    path_map = {'beauty_image':'Beauty', 'fashion_image':'Fashion', 'mobile_image':'Mobile'}\n",
    "    base_path = 'Train/' + path_map[path_segs[0]]\n",
    "    rel_path = path_segs[1]\n",
    "    rel_segs = rel_path.split('.')\n",
    "    if len(rel_segs) == 1:\n",
    "        rel_path = rel_path + '.jpg'\n",
    "    return base_path + '/' + str(cat)+ '/' + rel_path\n",
    "\n",
    "train_df['new_path'] = train_df.loc[:,['image_path','Category']].apply(lambda x: update_file_path(x),axis=1)\n",
    "train_df['meta_cat'] = train_df.loc[:,'image_path'].apply(lambda x: x.split('/')[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lood data for mobile categories (CHANGE here for other categories)\n",
    "ListCat = fasCat\n",
    "Cat_Size = len(fasCat)\n",
    "train_byCat = train_df.groupby('meta_cat')\n",
    "cur_cat = 'fashion_image'\n",
    "cat_train = train_byCat.get_group(cur_cat)\n",
    "cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "# input shape\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = applications.MobileNet(weights='imagenet', include_top=False, \n",
    "                                        input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "last_layer = base_model.output\n",
    "neck = GlobalAveragePooling2D()(last_layer)\n",
    "\n",
    "# Base Mobilenet   Model\n",
    "model = Model(inputs=base_model.input, outputs=neck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "base_dir = '/mnt/disks/NDSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator-1\n",
    "batch_size = 50\n",
    "generator = datagen.flow_from_dataframe(\n",
    "        dataframe=cat_train,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features for first 100k train samples\n",
    "num_samples = generator.n\n",
    "generator.reset()\n",
    "\n",
    "bottleneck_features_fashion = model.predict_generator(\n",
    "        generator, num_samples // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Fashion_bottleneck_part_1.npy', 'wb') as f:\n",
    "    np.save(f, bottleneck_features_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_train)-len(bottleneck_features_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fas_rem = cat_train.tail(2)\n",
    "fas_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator-1\n",
    "batch_size = 2\n",
    "generator_rem = datagen.flow_from_dataframe(\n",
    "        dataframe=fas_rem,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_rem = generator_rem.n\n",
    "generator_rem.reset()\n",
    "\n",
    "bottleneck_features_fashion_rem = model.predict_generator(\n",
    "        generator_rem, num_samples_rem // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(bottleneck_features_fashion_rem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(bottleneck_features_fashion[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(bottleneck_features_fashion[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate\n",
    "X_IMG_FAS_TRAIN = np.concatenate((bottleneck_features_fashion,bottleneck_features_fashion_rem), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IMG_FAS_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_IMG_FAS_TRAIN.npy', 'wb') as f:\n",
    "    np.save(f, X_IMG_FAS_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(X_IMG_FAS_TRAIN[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fas = X_IMG_FAS_TRAIN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fas_y = cat_train.Category.values\n",
    "fas_targets = np.zeros((n_fas, 58))\n",
    "fas_targets[np.arange(n_fas), fas_y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion model\n",
    "img_input = Input(shape=(1024,), name='img_input')\n",
    "x = Dropout(0.2)(img_input)\n",
    "x = Dense(1024, activation='relu', name= 'fc-1')(x) # dense 1\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation='relu')(x) #dense layer 2\n",
    "x = Dropout(0.5)(x)\n",
    "out = Dense(58, activation = 'softmax', name = 'out_layer')(x)\n",
    "\n",
    "# Base Mobilenet   Model\n",
    "\n",
    "Fas_model = Model(inputs=img_input, outputs=out)\n",
    "\n",
    "Fas_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "Fas_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NYRS_gen(X, y, batch_size):\n",
    "    \n",
    "    n_batches = math.floor(len(X) / batch_size)\n",
    "    \n",
    "    while True: \n",
    "        X,y = shuffle(X,y) # Shuffle the index.\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            \n",
    "            X_batch = X[i*batch_size:(i+1)*batch_size]\n",
    "            y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "import math\n",
    "\n",
    "N = len(X_IMG_FAS_TRAIN)\n",
    "\n",
    "X_IMG_FAS_TRAIN, fas_targets = shuffle(X_IMG_FAS_TRAIN, fas_targets)\n",
    "\n",
    "N_train = int(0.8*N)\n",
    "\n",
    "X_train = X_IMG_FAS_TRAIN[:N_train]\n",
    "y_train = fas_targets[:N_train]\n",
    "\n",
    "X_val = X_IMG_FAS_TRAIN[N_train:]\n",
    "y_val = fas_targets[N_train:]\n",
    "\n",
    "n_steps = len(X_IMG_FAS_TRAIN) // batch_size\n",
    "\n",
    "batch_gen = NYRS_gen(X_train, y_train, 32)\n",
    "\n",
    "history = Fas_model.fit_generator(batch_gen, epochs=10, \n",
    "                              steps_per_epoch=n_steps, \n",
    "                              validation_data=(X_val,y_val),\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update file paths accordingly in train_df\n",
    "test_df = test_data.copy()\n",
    "\n",
    "def update_test_file_path(inp):\n",
    "\n",
    "    path_segs = inp.split('/')\n",
    "    \n",
    "    path_map = {'beauty_image':'Beauty', 'fashion_image':'Fashion', 'mobile_image':'Mobile'}\n",
    "    base_path = 'Test/' + path_map[path_segs[0]]\n",
    "    rel_path = path_segs[1]\n",
    "    \n",
    "    rel_segs = rel_path.split('.')\n",
    "    if len(rel_segs) == 1:\n",
    "        rel_path = rel_path + '.jpg'\n",
    "        \n",
    "    return base_path + '/'  + rel_path\n",
    "\n",
    "test_df['new_path'] = test_df.loc[:,'image_path'].apply(lambda x: update_test_file_path(x))\n",
    "test_df['meta_cat'] = test_df.loc[:,'image_path'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55440, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lood data for mobile categories (CHANGE here for other categories)\n",
    "test_byCat = test_df.groupby('meta_cat')\n",
    "cur_cat = 'fashion_image'\n",
    "cat_test = test_byCat.get_group(cur_cat)\n",
    "cat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1. / 255)\n",
    "base_dir = '/mnt/disks/NDSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55440 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Generator-test\n",
    "batch_size = 50\n",
    "generator_test = datagen_test.flow_from_dataframe(\n",
    "        dataframe=cat_test,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108/1108 [==============================] - 1162s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Generate features for  test samples\n",
    "num_samples = generator_test.n\n",
    "generator_test.reset()\n",
    "\n",
    "bottleneck_features_fashion_test = model.predict_generator(\n",
    "        generator_test, num_samples // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_TEST_Fashion_bottleneck_part_1.npy', 'wb') as f:\n",
    "    np.save(f, bottleneck_features_fashion_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rem = len(cat_test)-len(bottleneck_features_fashion_test)\n",
    "N_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>image_path</th>\n",
       "      <th>new_path</th>\n",
       "      <th>meta_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131980</th>\n",
       "      <td>1825226347</td>\n",
       "      <td>stock baru atasan blouse wanita kemeja lengan ...</td>\n",
       "      <td>fashion_image/4bda1e64d3b4738cd2fcf67d52fd7b1f...</td>\n",
       "      <td>Test/Fashion/4bda1e64d3b4738cd2fcf67d52fd7b1f.jpg</td>\n",
       "      <td>fashion_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131981</th>\n",
       "      <td>1826413179</td>\n",
       "      <td>termurah kemeja wanita atasan baju kerja kanto...</td>\n",
       "      <td>fashion_image/85f1b1bc152062b1cc87c4e53b7af66b...</td>\n",
       "      <td>Test/Fashion/85f1b1bc152062b1cc87c4e53b7af66b.jpg</td>\n",
       "      <td>fashion_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131982</th>\n",
       "      <td>1827137407</td>\n",
       "      <td>rl women s summer chiffon shirt trumpet sleeve...</td>\n",
       "      <td>fashion_image/b39777140d57e04aadd0b4b07a86db8b...</td>\n",
       "      <td>Test/Fashion/b39777140d57e04aadd0b4b07a86db8b.jpg</td>\n",
       "      <td>fashion_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131983</th>\n",
       "      <td>1828540009</td>\n",
       "      <td>women casual 3 4 sleeve lace patchwork t shirt...</td>\n",
       "      <td>fashion_image/3c9f9b654b70b2c80e9f59acdc15a473...</td>\n",
       "      <td>Test/Fashion/3c9f9b654b70b2c80e9f59acdc15a473.jpg</td>\n",
       "      <td>fashion_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131984</th>\n",
       "      <td>1829477358</td>\n",
       "      <td>wanita s1017 kaos o neck dkny lengan pendek sp...</td>\n",
       "      <td>fashion_image/c61ba632459162c5bdc70ea1e6ba3ca1...</td>\n",
       "      <td>Test/Fashion/c61ba632459162c5bdc70ea1e6ba3ca1.jpg</td>\n",
       "      <td>fashion_image</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            itemid                                              title  \\\n",
       "131980  1825226347  stock baru atasan blouse wanita kemeja lengan ...   \n",
       "131981  1826413179  termurah kemeja wanita atasan baju kerja kanto...   \n",
       "131982  1827137407  rl women s summer chiffon shirt trumpet sleeve...   \n",
       "131983  1828540009  women casual 3 4 sleeve lace patchwork t shirt...   \n",
       "131984  1829477358  wanita s1017 kaos o neck dkny lengan pendek sp...   \n",
       "\n",
       "                                               image_path  \\\n",
       "131980  fashion_image/4bda1e64d3b4738cd2fcf67d52fd7b1f...   \n",
       "131981  fashion_image/85f1b1bc152062b1cc87c4e53b7af66b...   \n",
       "131982  fashion_image/b39777140d57e04aadd0b4b07a86db8b...   \n",
       "131983  fashion_image/3c9f9b654b70b2c80e9f59acdc15a473...   \n",
       "131984  fashion_image/c61ba632459162c5bdc70ea1e6ba3ca1...   \n",
       "\n",
       "                                                 new_path       meta_cat  \n",
       "131980  Test/Fashion/4bda1e64d3b4738cd2fcf67d52fd7b1f.jpg  fashion_image  \n",
       "131981  Test/Fashion/85f1b1bc152062b1cc87c4e53b7af66b.jpg  fashion_image  \n",
       "131982  Test/Fashion/b39777140d57e04aadd0b4b07a86db8b.jpg  fashion_image  \n",
       "131983  Test/Fashion/3c9f9b654b70b2c80e9f59acdc15a473.jpg  fashion_image  \n",
       "131984  Test/Fashion/c61ba632459162c5bdc70ea1e6ba3ca1.jpg  fashion_image  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fas_rem = cat_test.tail(N_rem)\n",
    "test_fas_rem.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator-1\n",
    "datagen_test_rem = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 1\n",
    "test_generator_rem = datagen_test_rem.flow_from_dataframe(\n",
    "        dataframe=test_fas_rem,\n",
    "        directory=base_dir,\n",
    "        x_col=\"new_path\",\n",
    "        y_col= None,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_rem = test_generator_rem.n\n",
    "test_generator_rem.reset()\n",
    "\n",
    "test_bottleneck_features_fashion_rem = model.predict_generator(\n",
    "        test_generator_rem, num_samples_rem // batch_size, verbose=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IMG_FAS_TEST = np.concatenate((bottleneck_features_fashion_test,test_bottleneck_features_fashion_rem), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_IMG_FAS_TEST.npy', 'wb') as f:\n",
    "    np.save(f, X_IMG_FAS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ----- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu_1)",
   "language": "python",
   "name": "tf_gpu_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
